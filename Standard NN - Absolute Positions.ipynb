{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e54cb788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from IPython.display import clear_output\n",
    "import scipy.io\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318b4b36",
   "metadata": {},
   "source": [
    "## Load Files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2826d612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files read =  1000\n"
     ]
    }
   ],
   "source": [
    "#Get the list of all files in the specified folder, and shuffle them to generalize:\n",
    "folder = np.array(os.listdir('CoPhe_Lab/1st_May'))\n",
    "folder = folder[np.random.permutation(len(folder))]\n",
    "folder_name = \"Cophe_Lab\\\\1st_May\\\\\" \n",
    "\n",
    "#Specify number of files to process:\n",
    "file_num = 1000\n",
    "print(\"Files in folder = \", file_num)\n",
    "_ = input(\"Press Enter to continue\")\n",
    "\n",
    "#Load the first matlab file:\n",
    "file = scipy.io.loadmat(folder_name + folder[0])\n",
    "\n",
    "#Initialize the array for the XA and YA positions\n",
    "all_Xpos = np.array(file['XA'])\n",
    "all_Ypos = np.array(file['YA'])\n",
    "\n",
    "#Get the Velocities along X-direction for current file:\n",
    "VXA = file['VXA']\n",
    "\n",
    "#Extract the first timestep, the initial velocity, and divide it by its magnitude to get the direction (1 or -1)\n",
    "Y = (VXA[:, 0]/abs(VXA[0, 0]))\n",
    "\n",
    "#Transform the 1 and -1 to a binary group corresponding to 1=>1 and -1=>0\n",
    "Y = ((Y + 1)/2).astype('int').reshape(all_Xpos.shape[0], 1)\n",
    "#Duplicate the 0 and 1 labels across the entire time axis:\n",
    "all_Y = np.tile(Y, all_Xpos.shape[1])\n",
    "\n",
    "#Initialize counter to count number of files processed:\n",
    "processed = 1\n",
    "\n",
    "for i in range(1, file_num):\n",
    "    \n",
    "    #Constant folder name:\n",
    "    folder_name = \"Cophe_Lab\\\\1st_May\\\\\"  \n",
    "    \n",
    "    #Get the MATLAB file, and follow similar steps as above:\n",
    "    file = scipy.io.loadmat(folder_name + folder[i])\n",
    "    X_position = np.array(file['XA'])\n",
    "    Y_position = np.array(file['YA'])\n",
    "    VXA = file['VXA']\n",
    "    Y = (VXA[:, 0]/abs(VXA[0, 0]))\n",
    "    Y = ((Y + 1)/2).astype('int').reshape(X_position.shape[0], 1)\n",
    "    Y = np.tile(Y, X_position.shape[1])\n",
    "    all_Xpos = np.concatenate((all_Xpos, X_position), axis = 1)\n",
    "    all_Ypos = np.concatenate((all_Ypos, Y_position), axis = 1)\n",
    "    all_Y = np.concatenate((all_Y, Y), axis = 1)\n",
    "    processed += 1\n",
    "    print(\"Files read = \", processed)\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cd375e",
   "metadata": {},
   "source": [
    "Right moving group is 1<br>\n",
    "Left moving group is 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb0fff6",
   "metadata": {},
   "source": [
    "#### Function to shuffle the order of the particles so that the each particle does not remain in the same index during each training step. This is to prevent the model constraining the particle's group to that specific index, we need to prevent this so that the model preserves the inherent properties of the collective "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33740e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_shuffle(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    order = np.random.permutation(len(a))\n",
    "    return a[order], b[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3de1217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_along_axis(a, axis):\n",
    "    idx = np.random.rand(*a.shape).argsort(axis=axis)\n",
    "    return np.take_along_axis(a,idx,axis=axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d816a2",
   "metadata": {},
   "source": [
    "### Generate the training data, X and Y labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e85b044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10010, 84)\n",
      "(10010, 42)\n"
     ]
    }
   ],
   "source": [
    "#Stack X and Y position vectors side by side like (X1, Y1), (X2, Y2) .....\n",
    "X = np.concatenate(((all_Xpos[:, 0]).reshape((42, 1)), (all_Ypos[:, 0]).reshape((42, 1))), axis = 1)\n",
    "Y = all_Y[:, 0]\n",
    "X_train, Y_train = generate_shuffle(X, Y)\n",
    "X_train = X_train.reshape((1, 84))\n",
    "Y_train = Y_train.reshape((1, 42))\n",
    "\n",
    "processed = 0\n",
    "\n",
    "for time in range(1, all_Xpos.shape[1]//100):\n",
    "    X = np.concatenate(((all_Xpos[:, time]).reshape((42, 1)), (all_Ypos[:, time]).reshape((42, 1))), axis = 1)\n",
    "    Y = all_Y[:, time]\n",
    "    #for i in range(42):\n",
    "    X_example, Y_example = generate_shuffle(X, Y)\n",
    "    X_example = X_example.reshape([1, -1])\n",
    "    Y_example = Y_example.reshape([1, -1])\n",
    "    X_train = np.concatenate((X_train, X_example), axis = 0)\n",
    "    Y_train = np.concatenate((Y_train, Y_example), axis = 0)\n",
    "    processed += 1\n",
    "    print(\"Instances processed = \", processed)\n",
    "    clear_output(wait=True)\n",
    "        \n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44b02d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10010, 84)\n",
      "(10010, 42)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3f786c",
   "metadata": {},
   "source": [
    "### Custom Loss Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "344695fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def penalize_false_positives(y_true, y_pred):\n",
    "    positives = tf.math.bincount(y_true)[1]\n",
    "    negatives = tf.size(y_true) - positives\n",
    "    pos_weight = (positives + negatives)/(2*positives)\n",
    "    neg_weight = (positives + negatives)/(2*negatives)\n",
    "    pos_weight = tf.cast(pos_weight, 'float32')\n",
    "    neg_weight = tf.cast(neg_weight, 'float32')\n",
    "    y_t = tf.cast(y_true, 'float32')\n",
    "    weight_vector = 0.01*pos_weight*(1 - y_t) + neg_weight\n",
    "    squared_difference = tf.square(y_t - y_pred) * weight_vector\n",
    "    return tf.reduce_mean(squared_difference, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8e7bda6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_small_errors(y_true, y_pred):\n",
    "    y_t = tf.cast(y_true, 'float32')\n",
    "    not_differentiable_error = tf.abs(y_pred - y_t)*10\n",
    "    differentiable_error = \n",
    "    return tf.reduce_sum(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf6f45a",
   "metadata": {},
   "source": [
    "# Model Definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a86dad47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer_nodes = [20, 50, 80, 50, 42]\n",
    "layer_nodes = [800, 2000, 3200, 2000, 42]\n",
    "dropout_probs = [0, 0.1, 0.2, 0.1, 0]\n",
    "\n",
    "#Activations:\n",
    "sigmoid = tf.keras.activations.sigmoid\n",
    "relu = tf.keras.activations.relu\n",
    "\n",
    "activations = [relu, relu, relu, relu, sigmoid]\n",
    "inputs = tf.keras.layers.Input(shape = (84,))\n",
    "layer_output = tf.keras.layers.Dense(units = layer_nodes[0], activation = 'relu')(inputs)\n",
    "layer_output = tf.keras.layers.Dropout(dropout_probs[0])(layer_output)\n",
    "layer_output = tf.keras.layers.BatchNormalization()(layer_output)\n",
    "\n",
    "for i in range(1, len(layer_nodes)-1):\n",
    "    layer_output = tf.keras.layers.Dense(units = layer_nodes[i], activation = activations[i])(layer_output)\n",
    "    layer_output = tf.keras.layers.Dropout(dropout_probs[i])(layer_output)\n",
    "    layer_output = tf.keras.layers.BatchNormalization()(layer_output)\n",
    "    \n",
    "layer_output = tf.keras.layers.Dense(units = layer_nodes[-1], activation = activations[-1])(layer_output)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4a64d669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 84)]              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 800)               68000     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 800)               0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 800)              3200      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 2000)              1602000   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 2000)              0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 2000)             8000      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 3200)              6403200   \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 3200)              0         \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 3200)             12800     \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 2000)              6402000   \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 2000)              0         \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 2000)             8000      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 42)                84042     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,591,242\n",
      "Trainable params: 14,575,242\n",
      "Non-trainable params: 16,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Model(inputs = inputs, outputs = layer_output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7f22ff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=5e-3), \n",
    "              loss = cut_small_errors,\n",
    "             metrics = [tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "455ebd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.0366 - precision_9: 0.9966\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0439 - precision_9: 0.9960\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0376 - precision_9: 0.9966\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0410 - precision_9: 0.9966\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0394 - precision_9: 0.9965\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0387 - precision_9: 0.9965\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0380 - precision_9: 0.9965\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0379 - precision_9: 0.9965\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0377 - precision_9: 0.9965\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0372 - precision_9: 0.9966\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0372 - precision_9: 0.9966\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0368 - precision_9: 0.9967\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0368 - precision_9: 0.9966\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0366 - precision_9: 0.9966\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0365 - precision_9: 0.9966\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0364 - precision_9: 0.9967\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0366 - precision_9: 0.9966\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0363 - precision_9: 0.9966\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0364 - precision_9: 0.9966\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0364 - precision_9: 0.9966\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0363 - precision_9: 0.9966\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0361 - precision_9: 0.9967\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0363 - precision_9: 0.9967\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0363 - precision_9: 0.9966\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0362 - precision_9: 0.9967\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0360 - precision_9: 0.9967\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0360 - precision_9: 0.9967\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0361 - precision_9: 0.9967\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0359 - precision_9: 0.9967\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0359 - precision_9: 0.9967\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0357 - precision_9: 0.9967\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0360 - precision_9: 0.9967\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0360 - precision_9: 0.9967\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0358 - precision_9: 0.9967\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0359 - precision_9: 0.9967\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0355 - precision_9: 0.9967\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0357 - precision_9: 0.9967\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0357 - precision_9: 0.9967\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0359 - precision_9: 0.9967\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0357 - precision_9: 0.9967\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0357 - precision_9: 0.9967\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0356 - precision_9: 0.9967\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0355 - precision_9: 0.9967\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0355 - precision_9: 0.9967\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0355 - precision_9: 0.9967\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0354 - precision_9: 0.9967\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0355 - precision_9: 0.9967\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0356 - precision_9: 0.9967\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0355 - precision_9: 0.9967\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0355 - precision_9: 0.9967\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0354 - precision_9: 0.9967\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0355 - precision_9: 0.9967\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0355 - precision_9: 0.9967\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0354 - precision_9: 0.9967\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0354 - precision_9: 0.9967\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0354 - precision_9: 0.9967\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0355 - precision_9: 0.9967\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0354 - precision_9: 0.9967\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0354 - precision_9: 0.9967\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0354 - precision_9: 0.9967\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0354 - precision_9: 0.9967\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0354 - precision_9: 0.9967\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0353 - precision_9: 0.9967\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0353 - precision_9: 0.9967\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0352 - precision_9: 0.9967\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0354 - precision_9: 0.9967\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0352 - precision_9: 0.9967\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0353 - precision_9: 0.9967\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0352 - precision_9: 0.9967\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0352 - precision_9: 0.9967\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0352 - precision_9: 0.9967\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0354 - precision_9: 0.9967\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0353 - precision_9: 0.9967\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0350 - precision_9: 0.9967\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0352 - precision_9: 0.9967\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0353 - precision_9: 0.9967\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0352 - precision_9: 0.9967\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0351 - precision_9: 0.9967\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0353 - precision_9: 0.9967\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0352 - precision_9: 0.9967\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0351 - precision_9: 0.9967\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0349 - precision_9: 0.9967\n",
      "Epoch 83/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step - loss: 0.0351 - precision_9: 0.9967\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0350 - precision_9: 0.9967\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0351 - precision_9: 0.9967\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0350 - precision_9: 0.9967\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0349 - precision_9: 0.9967\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0351 - precision_9: 0.9967\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0350 - precision_9: 0.9967\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0350 - precision_9: 0.9967\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0350 - precision_9: 0.9967\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0348 - precision_9: 0.9967\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0347 - precision_9: 0.9967\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0349 - precision_9: 0.9967\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0350 - precision_9: 0.9967\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0350 - precision_9: 0.9967\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0350 - precision_9: 0.9967\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0351 - precision_9: 0.9967\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0351 - precision_9: 0.9967\n",
      "Epoch 100/500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-137-10993fc9a65b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(x = X_train, y = Y_train, batch_size = X_train.shape[0], epochs = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "24ee6d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5330c4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ed6c4381",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_standard.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
